{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352c50dc-3544-40fa-b554-7591cba5ca2c",
   "metadata": {},
   "source": [
    "![Banner](banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf7043-ba66-49e1-9216-3c80e3b64568",
   "metadata": {},
   "source": [
    "# Exercise 1: Introduction into vector search and embeddings\n",
    "\n",
    "This notebook deals with the implementation and management of vector searches in a database. Vector search is a powerful tool to find semantic similarities in large data sets. In contrast to classical search methods, which are based on exact matches, vector search makes it possible to find similar objects even if they are not identical. This method is used in applications such as image, text or product recommendation systems.\n",
    "\n",
    "### Aim of this notebook\n",
    "This exercise demonstrates how vector data can be stored in a database and made accessible through similarity searches. The main steps include:\n",
    "\n",
    "- Setting up a dedicated tablespace and user for the vector database.\n",
    "- Loading and managing ONNX models to generate embeddings.\n",
    "- Implementing triggers to automatically generate embeddings when new data is inserted into the database. \n",
    "- Performing similarity searches to identify data sets that are similar to a given input value.\n",
    "- Optimizing the vector index and analyzing performance.\n",
    "\n",
    "### Data\n",
    "The synthetic data used in this exercise represents real estate information. Each row in the table represents a property and contains the following attributes:\n",
    "\n",
    "1. **PID:** A unique identifier (ID) for each property.\n",
    "2. **TYP:** The type of property, e.g. \"apartment building\", \"detached house\", \"flat\", \"bungalow\", \"semi-detached house\" etc.\n",
    "3. **PREIS:** The selling price of the property in euros.\n",
    "4. **ZIMMER:** The number of bedrooms in the property.\n",
    "5. **STADT:** The name of the city in which the property is located.\n",
    "6. **LAND:** The federal state in which the property is located, e.g. \"Schleswig-Holstein\", \"Baden-Württemberg\", \"Thuringia\" etc.\n",
    "7. **BESCHREIBUNG:** A textual description of the property and its features.\n",
    "\n",
    "These attributes provide a variety of features that can be used for vector search. The attribute ‘description’ is converted into an embedding in this exercise to enable a semantic search based on similarities between properties.",
    "\n",
    "### Learning targets\n",
    "After completing this exercise, you should:\n",
    "\n",
    "1. understand how embeddings are generated and managed in a database.\n",
    "2. be able to perform vector searches with high accuracy and efficiency.\n",
    "3. know how to optimize storage resources and evaluate the performance of vector indices.\n",
    "\n",
    "Have fun & success!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4197696a-4ddd-42f2-969d-5690c5e7e20f",
   "metadata": {},
   "source": [
    "## Preparation: Setting up the environment and connecting to the Oracle database\n",
    "\n",
    "To begin with, the working environment is set up and a connection to an Oracle database is established. This includes the installation of the necessary Python packages and the initialization of the Oracle client.\n",
    "\n",
    "#### Installed packages:\n",
    "- `oracledb`: Required to connect to Oracle databases and execute SQL queries.\n",
    "- `ipython-sql`: Enables the use of SQL in Jupyter notebooks.\n",
    "- `pandas`: Used for data processing and analysis. Here it is used to load and manage the results of SQL queries in DataFrames.\n",
    "\n",
    "#### Code-Details:\n",
    "- The Oracle client is initialized with `oracledb.init_oracle_client`, where the directory for the Oracle libraries is specified.\n",
    "- The environment variables `HOST_NAME` and `PDB_NAME` are used to create the connection string (`dsn`) for the Oracle database. This contains the host name and the Pluggable Database Name (PDB), which are required to address the database.\n",
    "- A connection to the Oracle database is established with the user `vector` and the password `vector`. The connection string combines host and PDB, which are stored in the environment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe7a88b-c79c-44a0-b9b7-c1862442dd48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting oracledb\n",
      "  Downloading oracledb-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: cryptography>=3.2.1 in /opt/conda/lib/python3.11/site-packages (from oracledb) (42.0.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=3.2.1->oracledb) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.2.1->oracledb) (2.22)\n",
      "Downloading oracledb-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: oracledb\n",
      "Successfully installed oracledb-2.5.1\n",
      "Collecting ipython-sql\n",
      "  Downloading ipython_sql-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting prettytable (from ipython-sql)\n",
      "  Downloading prettytable-3.12.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.11/site-packages (from ipython-sql) (8.24.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in /opt/conda/lib/python3.11/site-packages (from ipython-sql) (2.0.30)\n",
      "Collecting sqlparse (from ipython-sql)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.11/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy>=2.0->ipython-sql) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy>=2.0->ipython-sql) (3.0.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (4.9.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prettytable->ipython-sql) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->ipython-sql) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->ipython-sql) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->ipython-sql) (0.2.2)\n",
      "Downloading ipython_sql-0.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading prettytable-3.12.0-py3-none-any.whl (31 kB)\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sqlparse, prettytable, ipython-sql\n",
      "Successfully installed ipython-sql-0.5.0 prettytable-3.12.0 sqlparse-0.5.3\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install oracledb \n",
    "!pip install ipython-sql\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd65e8a-9b0d-4540-8062-5a75c4cbabe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db23ai.subbb3fff175.quickcluster.oraclevcn.com/marcel.subbb3fff175.quickcluster.oraclevcn.com\n"
     ]
    }
   ],
   "source": [
    "import oracledb\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "pd.options.display.max_colwidth = 800\n",
    "\n",
    "d = '/home/jovyan/.jupyter/instantclient_23_5'\n",
    "oracledb.init_oracle_client(lib_dir=d)\n",
    "host = os.environ.get('HOST_NAME')\n",
    "pdb = os.environ.get('PDB_NAME')\n",
    "cs = host + '/' + pdb\n",
    "print(cs)\n",
    "# should be something like 'db23ai.subbb3fff175.quickcluster.oraclevcn.com/michael.subbb3fff175.quickcluster.oraclevcn.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f96446-1c9f-4ac5-b5a6-f6b9e430a5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<oracledb.Connection to vector@db23ai.subbb3fff175.quickcluster.oraclevcn.com/marcel.subbb3fff175.quickcluster.oraclevcn.com>\n"
     ]
    }
   ],
   "source": [
    "connection = oracledb.connect(user='vector', password='vector', dsn=cs)\n",
    "print(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85166ae9-675e-4a72-85df-acfaafa92392",
   "metadata": {},
   "source": [
    "These commands optimize the memory for the in-memory column store (16 GB) and the vector store (12 GB) to enable fast queries and efficient vector data searches."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d1ddf5f-9e24-4c66-b926-2f7f183330b5",
   "metadata": {},
   "source": [
    "alter system inmemory_size=16G scope=both;\n",
    "alter system set vector_memory_size=12G scope=both;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a817758-16cd-4110-830a-7a9af231adea",
   "metadata": {},
   "source": [
    "## Script 01: Creating the tablespace and user - ⚠️Skript does NOT need to be executed⚠️\n",
    "\n",
    "In this section, the database environment is prepared by creating a new tablespace and a user.\n",
    "\n",
    "- **Tablespace:** The tablespace `tbsvec` is created with an initial size of 40 GB and can expand automatically. \n",
    "- **User \"vector\":** The user `vector` is created and given full access to the tablespace `tbsvec`.\n",
    "- **Roles and permissions:** The user `vector` is assigned specific roles, including permission to create mining models and access to the directory `vec_dump`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "55f0e235-7bda-4e10-a70f-70bb50a9d828",
   "metadata": {},
   "source": [
    "-- Create Tablespace\n",
    "CREATE TABLESPACE tbsvec\n",
    "DATAFILE SIZE 40G AUTOEXTEND ON\n",
    "EXTENT MANAGEMENT LOCAL\n",
    "SEGMENT SPACE MANAGEMENT AUTO;\n",
    "-- Create User \"vector\"\n",
    "DROP USER vector CASCADE;\n",
    "CREATE USER vector IDENTIFIED BY vector DEFAULT TABLESPACE tbsvec\n",
    "QUOTA UNLIMITED ON tbsvec;\n",
    "GRANT DB_DEVELOPER_ROLE TO vector;\n",
    "GRANT CREATE MINING MODEL TO vector;\n",
    "GRANT CREATE CREDENTIAL TO vector;\n",
    "CREATE OR REPLACE DIRECTORY vec_dump AS '/u03/vecdump';\n",
    "GRANT READ, WRITE ON DIRECTORY vec_dump TO vector;\n",
    "GRANT SELECT ON VECSYS.VECTOR$INDEX TO VECTOR;\n",
    "-- CREATE PROFILE only_one_connection limit sessions_per_user 1;\n",
    "-- ALTER USER vector PROFILE only_one_connection;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f773dd-7f46-4c0a-93de-624cc91604a8",
   "metadata": {},
   "source": [
    "<a id='modellverwaltung'></a>\n",
    "## Skript 02: loading an ONNX-Model\n",
    "\n",
    "In this section, the ONNX model `distil_v2` is loaded into the database. The model is used to create embeddings and works with cosine similarity as a distance function.\n",
    "\n",
    "### What is ONNX?\n",
    "\n",
    "**ONNX** (Open Neural Network Exchange) is an open format developed to enable interoperability between different deep learning frameworks. With ONNX, models can be seamlessly transferred between different tools and platforms. It supports a variety of operations and allows trained models to be used efficiently in production environments or optimized on other hardware platforms such as GPUs.\n",
    "\n",
    "### choice of models: distiluse-base-multilingual-cased-v2\n",
    "\n",
    "In exercise 1, we use the **`distiluse-base-multilingual-cased-v2`** model from the `sentence-transformers` library. This model was chosen because it is optimized for multilingual use cases and is particularly well suited for semantic text similarity tasks. It supports multiple languages and offers high performance in the calculation of vector embeddings. \n",
    "\n",
    "### Note: Executing SQL code in a Jupyter notebook with Python\n",
    "\n",
    "1. **Define SQL code**: SQL commands are saved as strings in Python variables.\n",
    "2. **Execute SQL**: The SQL code is executed with `cursor.execute(sql)`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "40593e6a-d7ea-4001-bdb8-0d816ad061ca",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "-- distil_v2.onnx is Hugging Face's embedding model sentence-transformers/distiluse-base-multilingual-cased-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90123bfd-ea36-4455-a3c9-cc5620be4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "BEGIN\n",
    " DBMS_VECTOR.DROP_ONNX_MODEL(\n",
    "  'distil_model',\n",
    "  force => true \n",
    ")\n",
    ";\n",
    "\n",
    " DBMS_VECTOR.LOAD_ONNX_MODEL( \n",
    "  'VEC_DUMP', \n",
    "  'distil_v2.onnx', \n",
    "  'distil_model', \n",
    "   JSON('{\"function\":\"embedding\",\"embeddingOutput\":\"embedding\",\"input\":{\"input\": [\"DATA\"]}}') \n",
    ")\n",
    ";\n",
    "END;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tic = time.perf_counter()\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")\n",
    "toc = time.perf_counter()\n",
    "print(f\"Loading model took {toc - tic:0.4f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec45be-7e33-46b0-aaae-e3e9e04a06b0",
   "metadata": {},
   "source": [
    "## Script 02: Load another ONNX model \"minilm\"\n",
    "\n",
    "In this step, the ONNX model `minilml6_v2` is loaded into the database. This model also generates embeddings and uses the same input configuration as the previous model.\n",
    "\n",
    "> **Note:** The model `minilml6_model` is only loaded in this notebook, but is only actually used in **Exercise 2**. In this exercise, only the model `distiluse-base-multilingual-cased-v2` is used to calculate the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bfcc2b-94df-49fc-8daa-77fc62d3ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql= \"\"\"\n",
    "BEGIN\n",
    "DBMS_VECTOR.DROP_ONNX_MODEL( \n",
    "  'minilml6_model', \n",
    "  force => true \n",
    ")\n",
    ";\n",
    " DBMS_VECTOR.LOAD_ONNX_MODEL( \n",
    "  'VEC_DUMP', \n",
    "  'minilml6_v2.onnx', \n",
    "  'minilml6_model', \n",
    "   JSON('{\"function\":\"embedding\",\"embeddingOutput\":\"embedding\",\"input\":{\"input\": [\"DATA\"]}}') \n",
    ")\n",
    ";\n",
    "END;\n",
    "\"\"\"\n",
    "\n",
    "tic = time.perf_counter()\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")\n",
    "toc = time.perf_counter()\n",
    "print(f\"Loading model took {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e519a05a-f5d6-47b6-9c35-a7f45a88acb2",
   "metadata": {},
   "source": [
    "## Script 02a: Query model information\n",
 "\n",
 "In this section, SQL queries are executed to retrieve information about the loaded models. Details such as the model name, the mining function, the algorithm, the model size and specific attributes of the models are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e0628-73a5-4751-8b2d-0fc3a9a2631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql= \"\"\"\n",
    "SELECT MODEL_NAME, MINING_FUNCTION, ALGORITHM,\n",
    "ALGORITHM_TYPE, MODEL_SIZE/1024/1024 \"SIZE [MB]\"\n",
    "FROM user_mining_models\n",
    "ORDER BY MODEL_NAME\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql=sql, con=connection)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6157c-21d1-429f-9963-9fd251c94b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "SELECT model_name, attribute_name, attribute_type, data_type, vector_info\n",
    "FROM user_mining_model_attributes\n",
    "ORDER BY MODEL_NAME\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql=sql, con=connection)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc0792-da4d-4ac0-b558-43a1d0b615d1",
   "metadata": {},
   "source": [
    "## Script 03: Trigger for automatic embeddings\n",
    "\n",
    "**Functionality:**\n",
    "- Each time data is inserted or updated in the `real estate` table, the `description` field is used to generate an embedding.\n",
    "- The generated embedding is saved in the corresponding `EMBED` column of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d81440-12fd-440e-b347-1747eec8680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hint: Trigger should be deactivated before bigger INSERT operations, or else there would be no parallelisation.\n",
    "sql=\"\"\"\n",
    "CREATE OR REPLACE TRIGGER immobilien_embed\n",
    "BEFORE INSERT OR UPDATE ON immobilien\n",
    "FOR EACH ROW\n",
    "DECLARE\n",
    "params clob;\n",
    "BEGIN\n",
    "  params := '{\"provider\":\"database\",\"model\":\"distil_model\"}';\n",
    "  :new.embed := DBMS_VECTOR.UTL_TO_EMBEDDING(:new.beschreibung,json(params));\n",
    "END;\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72532fe0-5cf4-4c67-821c-b8aafcf3c3c8",
   "metadata": {},
   "source": [
    "## Script 04: Parallel calculation and storage of embeddings\n",
    "\n",
    "This section executes an SQL procedure that temporarily deactivates the `IMMOBILIEN_EMBED` trigger to enable parallel calculation and updating of embeddings in the `immobilien` table. For entries where the `EMBED` column is still empty, an embedding is generated and saved based on the `distil_model` and the `description` text field.\n",
    "\n",
    "**Execution:**\n",
    "1. the `IMMOBILIEN_EMBED` trigger is deactivated.\n",
    "2. the `EMBED` column is filled with newly calculated embeddings. \n",
    "3. In addition, a parallel mode for DDL operations is enforced to improve performance.\n",
    "4. The trigger `IMMOBILIEN_EMBED` is reactivated.\n",
    "\n",
    "\n",
    "**The execution of this step takes about 6 minutes at parallelization level 6.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d906d0af-8a66-4e48-b2d4-25628c034228",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "BEGIN\n",
    "EXECUTE IMMEDIATE ('ALTER TRIGGER IMMOBILIEN_EMBED DISABLE');\n",
    "UPDATE /*+ enable_parallel_dml parallel(tim,9) */ immobilien tim \n",
    "SET EMBED=TO_VECTOR(VECTOR_EMBEDDING(distil_model USING beschreibung AS DATA))\n",
    "WHERE EMBED IS NULL;\n",
    "COMMIT;\n",
    "EXECUTE IMMEDIATE ('ALTER TRIGGER IMMOBILIEN_EMBED ENABLE');\n",
    "END; \"\"\"\n",
    "\n",
    "tic = time.perf_counter()\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")\n",
    "toc = time.perf_counter()\n",
    "print(f\"Vectorizing data took {toc - tic:0.4f} seconds\")"
   ]
  },
{
   "cell_type": "markdown",
   "id": "560f37ca-9d53-4177-8dbc-e93f5ebc4cd9",
   "metadata": {},
   "source": [
    "## Experiments:\n",
    "* How long does it take to create embeddings with a different LLM, like minilml6 ?\n",
    "* How long does it take to create embeddings with a different degree of parallelism, like 12 ?\n",
    "* How long does it take to create embeddings through an external GPU based provider ?\n",
    "\n",
    "For time reasons, we will reduce the processed amount of data to 200 rows.\n",
    "Data will NOT be committed, e.g. written to the database table.\n",
    "\n",
    "Please take into account that You are not alone on the system. You are sharing CPU cores and one GPU with others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fab4ce52-7416-40e9-b339-a2000004f336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n",
      "Vectorizing data took 12.1250 seconds\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "BEGIN\n",
    "EXECUTE IMMEDIATE ('ALTER TRIGGER IMMOBILIEN_EMBED DISABLE');\n",
    "UPDATE /*+ enable_parallel_dml parallel(tim,12) */ immobilien tim \n",
    "SET EMBED=TO_VECTOR(VECTOR_EMBEDDING(minilml6_model USING beschreibung AS DATA))\n",
    "WHERE ROWNUM < 200;\n",
    "ROLLBACK;\n",
    "EXECUTE IMMEDIATE ('ALTER TRIGGER IMMOBILIEN_EMBED ENABLE');\n",
    "END; \"\"\"\n",
    "\n",
    "tic = time.perf_counter()\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")\n",
    "toc = time.perf_counter()\n",
    "print(f\"Vectorizing data took {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9c85567-8a93-4155-9c4e-8aa6e08f05e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n",
      "Vectorizing data took 31.7187 seconds\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "DECLARE\n",
    "  params clob;\n",
    "BEGIN\n",
    "params := '{\"provider\":\"ollama\",'||\n",
    "  '\"host\"    :\"local\", '||\n",
    "  '\"url\"     : \"http://ollama.meinnetzwerk.com/api/embeddings\", '||\n",
    "  '\"transfer_timeout\": 120, '|| -- cannot do longer than the operating system\n",
    "  '\"model\"   : \"all-minilm:latest\" '||\n",
    "  '}';\n",
    "\n",
    "EXECUTE IMMEDIATE ('ALTER TRIGGER IMMOBILIEN_EMBED DISABLE');\n",
    "UPDATE IMMOBILIEN TIM\n",
    "SET EMBED=DBMS_VECTOR.UTL_TO_EMBEDDING(beschreibung,json(params))\n",
    "WHERE ROWNUM < 200;\n",
    "ROLLBACK;\n",
    "EXECUTE IMMEDIATE ('ALTER TRIGGER IMMOBILIEN_EMBED ENABLE');\n",
    "END; \"\"\"\n",
    "\n",
    "tic = time.perf_counter()\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")\n",
    "toc = time.perf_counter()\n",
    "print(f\"Vectorizing data took {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4fb8e-38be-49e3-9cca-3f8152106d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "BEGIN\n",
    "EXECUTE IMMEDIATE ('drop index if exists IDX_IMMOBILIEN_EMBED');\n",
    "EXECUTE IMMEDIATE ('ALTER SESSION FORCE PARALLEL DDL PARALLEL 4');\n",
    "END;\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdfc19d-a0ed-4d0f-8404-6e67e4aa0ecd",
   "metadata": {},
   "source": [
    "## Script 04a: Creation and verification of the vector index\n",
    "In this section, a vector index is created on the `EMBED` column of the `real estate` table to perform efficient similarity searches based on vector data.\n",
    "\n",
    "**Procedure:**\n",
    "1. **Creation of the vector index:** The index `IDX_IMMOBILIEN_EMBED` is created to perform fast and precise searches.\n",
    "2. **Check the index:** An SQL query is executed to check the newly created index and confirm its type and subtype. \n",
    "3. **Retrieving the index parameters:** The parameters of the vector index are retrieved as JSON data and displayed in a clear format.\n",
    "\n",
    "The index creation and subsequent analysis ensure that the database is optimally prepared for the vector search.\n",
    "\n",
    "### Theory: Cosine similarity and cosine distance\n",
    "\n",
    " From mathematics: scalar product of two vectors\n",
    " \n",
    " $$ \\vec a \\cdot \\vec b = |\\vec a| \\cdot |\\vec b| \\cdot cos\\theta$$\n",
    " \n",
    " $ cos\\theta = \\frac{\\vec a \\cdot \\vec b}{|\\vec a| \\cdot |\\vec b|}$ => cosine similarity\n",
    " \n",
    " $ 1 - cos\\theta $ => cosine distance (The \"COSINE\" in the VECTOR_DISTANCE function above)\n",
    " \n",
    " So the closer to 0 the cosine distance, the more similar the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d60c3e-11a8-4e79-b3a1-2c2f17c2e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "create vector index IDX_IMMOBILIEN_EMBED on IMMOBILIEN(embed)\n",
    "organization INMEMORY NEIGHBOR GRAPH\n",
    "distance COSINE \n",
    "with target accuracy 95\n",
    "\"\"\"\n",
    "\n",
    "tic = time.perf_counter()\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")\n",
    "toc = time.perf_counter()\n",
    "print(f\"Vector index creation took {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db75ab25-6696-42db-b23c-5fb819e45623",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql= \"\"\"\n",
    "SELECT INDEX_NAME, INDEX_TYPE, INDEX_SUBTYPE\n",
    "FROM USER_INDEXES\n",
    "WHERE INDEX_NAME='IDX_IMMOBILIEN_EMBED'\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql=sql, con=connection)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ab9fd-b2b6-49f3-a4c0-d8f9a6f1c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql= \"\"\"\n",
    "SELECT JSON_SERIALIZE(IDX_PARAMS returning varchar2) \"IDX_Params\"\n",
    "FROM VECSYS.VECTOR$INDEX\n",
    "where IDX_NAME = 'IDX_IMMOBILIEN_EMBED'\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    res, =cursor.fetchone()\n",
    "    json_obj = json.loads(res)\n",
    "    pretty= json.dumps(json_obj, indent=4)\n",
    "    print(pretty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73851a09-f205-4bbf-b4eb-89016d353431",
   "metadata": {},
   "source": [
    "## Script 04b Create vector index, partitioned by vector distance\n",
    "This section describes the steps for creating a new vector index and then analyzing its parameters. The existing index is first removed to ensure that the new index can be created without conflicts.\n",
    "These steps ensure that an optimized vector index is created that enables high performance in vector searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c948f-3104-4f16-a0b1-d08687d3eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "BEGIN\n",
    "EXECUTE IMMEDIATE ('drop index if exists IDX_IMMOBILIEN_EMBED');\n",
    "EXECUTE IMMEDIATE ('ALTER SESSION FORCE PARALLEL DDL PARALLEL 4');\n",
    "END;\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9704b-d23c-409d-85ad-d7a2272c1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "create vector index IDX_IMMOBILIEN_EMBED on IMMOBILIEN(embed)\n",
    "organization NEIGHBOR PARTITIONS \n",
    "distance COSINE \n",
    "with target accuracy 95\n",
    "\"\"\"\n",
    "\n",
    "tic = time.perf_counter()\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")\n",
    "toc = time.perf_counter()\n",
    "print(f\"Vector index creation took {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b17b5-8c95-450c-a213-db67b4b061da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql= \"\"\"\n",
    "SELECT INDEX_NAME, INDEX_TYPE, INDEX_SUBTYPE\n",
    "FROM USER_INDEXES\n",
    "WHERE INDEX_NAME='IDX_IMMOBILIEN_EMBED'\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql=sql, con=connection)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93924d15-cf67-4512-a0bd-20b5ae378f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql= \"\"\"\n",
    "SELECT JSON_SERIALIZE(IDX_PARAMS returning varchar2) \"IDX_Params\"\n",
    "FROM VECSYS.VECTOR$INDEX\n",
    "where IDX_NAME = 'IDX_IMMOBILIEN_EMBED'\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    res, =cursor.fetchone()\n",
    "    json_obj = json.loads(res)\n",
    "    pretty= json.dumps(json_obj, indent=4)\n",
    "    print(pretty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d617002-d0c8-4104-a775-21990b28526c",
   "metadata": {},
   "source": [
    "## Script 05: Similarity search based on embeddings\n",
    "\n",
    "In this section, we perform a similarity search to find the five most similar single-family homes in the `real estate` table based on an input text.\n",
    "\n",
    "**Steps:**\n",
    "1. a text input is stored in a variable `searchtext` and converted into an embedding. \n",
    "2. the `real estate` table is searched for entries of the type `single-family house`.\n",
    "3. the entries are sorted according to their similarity to the entered text, based on the cosine similarity of the embeddings.\n",
    "4. the five most similar entries are displayed with a target accuracy of 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3a64615-bf6f-4f97-951a-0ffb612c92dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert search text here with medical care and sauna\n"
     ]
    }
   ],
   "source": [
    "suchtext = input(\"Suchtext hier einfügen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dad5f9-131d-491b-80b6-d56a2809dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql1=\"SELECT vector_embedding(distil_model using :suchtext as data) from dual\"\n",
    "\n",
    "sql2=\"\"\"\n",
    "select pid, typ, beschreibung, embed <=> :query_vector as cosine_dist\n",
    "from immobilien\n",
    "where typ='Einfamilienhaus'\n",
    "order by cosine_dist\n",
    "fetch approx first 5 rows only with target accuracy 80\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    query_vector = cursor.var(oracledb.DB_TYPE_VECTOR)    \n",
    "    cursor.execute(sql1, suchtext=suchtext)\n",
    "    query_vector, =cursor.fetchone()\n",
    "    \n",
    "    df = pd.read_sql(sql2, params={'query_vector': query_vector}, con=connection)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727db440-95cd-458c-bb7a-3d7d9036b86c",
   "metadata": {},
   "source": [
    "## Excursus: Creating a full-text index and comparative query\n",
    "\n",
    "The example is intended to show that a full-text search operates and is structured differently to a vector search. The full-text search finds individual words in texts, but also word stems and similar words spelled differently using a fuzzy search. Synonyms or entire phrases such as \"medical care\" instead of \"medical practices\" must be trained manually, e.g. by creating and using a thesaurus for each specialist area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86c3974c-ba4e-4b36-9522-f5382129394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n",
      "Text index creation took 2.1615 seconds\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE INDEX idx_text on immobilien(beschreibung) indextype is ctxsys.context\n",
    "'''\n",
    "tic = time.perf_counter()\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")\n",
    "toc = time.perf_counter()\n",
    "print(f\"Text index creation took {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738c0d9-2092-4796-8d8f-94e86a0f7ee3",
   "metadata": {},
   "source": [
    "The index has been created, now we create a simple thesaurus with one synonym and two nestings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac69c173-a16c-4a20-a139-6142f82aa846",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "begin\n",
    "  ctx_thes.create_thesaurus(\n",
    "    name     => 'MEIN_THESAURUS',\n",
    "    casesens => false\n",
    "  );\n",
    "  ctx_thes.create_relation('MEIN_THESAURUS', 'Whirlpool', 'SYN', 'Jacuzzi');\n",
    "  ctx_thes.create_relation('MEIN_THESAURUS', 'Wellness', 'NT', 'Sauna');\n",
    "  ctx_thes.create_relation('MEIN_THESAURUS', 'Wellness', 'NT', 'Jacuzzi');\n",
    "end;\n",
    "'''\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a2fd0-63f6-4028-a12f-9112792a7588",
   "metadata": {},
   "source": [
    "And now we use a classic full-text search with thesaurus nesting. Individual words can be linked with AND / OR syntax or separated by commas. Free text works less well unless this has also been provided for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d65c32-e427-45e2-aac5-ebbdf381e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "suchtext = input(\"enter search text here\")\n",
    "suchtext = \"NT(\"+suchtext+\", 10, MEIN_THESAURUS)\"\n",
    "sql = '''\n",
    "SELECT pid, typ, beschreibung, score(1) FROM immobilien \n",
    "              WHERE CONTAINS(beschreibung, :suchtext, 1) > 0\n",
    "              order by score(1)\n",
    "'''\n",
    "with connection.cursor() as cursor:     \n",
    "    \n",
    "    df = pd.read_sql(sql, params={'suchtext': suchtext}, con=connection)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2b0f4-d801-49ab-a092-5dacb29e6820",
   "metadata": {},
   "source": [
    "## Script 05: Custom similarity search\n",
    "\n",
    "In this section, the vector-based similarity search is further refined by only returning entries whose **Cosine distance** to the search vector is less than or equal to 0.5. This ensures that only properties that are particularly similar to the search vector are displayed.\n",
    "\n",
    "### Steps:\n",
    "1. **Calculating the query vector:** The search text is used again to generate an embedding vector that serves as a reference for the search.\n",
    "2. **Filtering by cosine distance:** In contrast to the previous search, only entries whose cosine distance to the search vector is 0.5 or less are returned here. This restricts the results to highly similar single-family homes.\n",
    "3. **Top 5 results:** The five most similar entries based on this filter are returned, with a target accuracy of 80%.\n",
    "\n",
    "This query makes it possible to find only those properties that are particularly close to the search vector in terms of the content of the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c884a9-7ae2-4209-89f1-a2a45d863330",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql2=\"\"\"\n",
    "SELECT * FROM\n",
    "(\n",
    "SELECT pid, typ, beschreibung, VECTOR_DISTANCE(embed, :query_vector, COSINE) AS COSINE_DIST\n",
    "FROM immobilien\n",
    ")\n",
    "WHERE typ='Einfamilienhaus' and COSINE_DIST <= 0.5\n",
    "ORDER BY COSINE_DIST\n",
    "FETCH APPROX FIRST 5 ROWS ONLY WITH TARGET ACCURACY 80\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql2, params={'query_vector': query_vector}, con=connection)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac17b89-b326-4f84-b914-ea2419050774",
   "metadata": {},
   "source": [
    "## Script 05: Advanced similarity search\n",
    "\n",
    "In this third section, the similarity search is performed again, but this time with a relaxed condition for the **cosine distance**. While the previous search only considered entries with a maximum cosine distance of 0.5, this search expands the filter to include entries with a cosine distance of up to 0.9. This makes it possible to capture a larger number of potentially relevant entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fd6cb-94b6-438d-918c-525db4e70dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql2=\"\"\"\n",
    "SELECT * FROM\n",
    "(\n",
    "SELECT pid, typ, beschreibung, VECTOR_DISTANCE(embed, :query_vector, COSINE) AS COSINE_DIST\n",
    "FROM immobilien\n",
    ")\n",
    "WHERE COSINE_DIST <= 0.9\n",
    "order by COSINE_DIST \n",
    "FETCH FIRST 5 ROWS ONLY\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql2, params={'query_vector': query_vector}, con=connection)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1751a3-5ef9-42cb-a514-3321a507df31",
   "metadata": {},
   "source": [
    "## Index accuracy check\n",
    "\n",
    "In this section, the accuracy of the created vector index is checked. The Oracle function `dbms_vector.index_accuracy_query` is used to measure the **target accuracy** of the index in a similarity search.\n",
    "\n",
    "### Steps:\n",
    "1. **query of the index:** A query is executed to check the accuracy of the vector index `IDX_IMMOBILIEN_EMBED` based on the specified search vector.\n",
    "2. **Parameter:** \n",
    " - The search vector (`query_vector`) serves as the basis for the accuracy measurement. \n",
    " - The query returns the accuracy for the top 10 results, where a target accuracy of 80% is set.\n",
    "3. **Result:** The actual accuracy of the index is returned to assess whether the index meets the requirements.\n",
    "\n",
    "This check is to ensure that the vector index provides sufficient accuracy when searching for similar properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bbc7b9-a58e-4c40-9504-390571887ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "select dbms_vector.index_accuracy_query( \n",
    "  OWNER_NAME => 'VECTOR',\n",
    "  INDEX_NAME => 'IDX_IMMOBILIEN_EMBED',\n",
    "  qv => :query_vector,\n",
    "  top_K => 10,\n",
    "  target_accuracy => 80 ) as accuracy from dual\n",
    "\"\"\"\n",
    "with connection.cursor() as cursor:  \n",
    "    cursor.execute(sql, query_vector=query_vector)\n",
    "    res, = cursor.fetchone()\n",
    "    print (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861bb9d8-af68-42b7-a84a-e251ead684ad",
   "metadata": {},
   "source": [
    "## Checking the vector memory pool\n",
    "\n",
    "This section checks the memory status of the **vector memory pool** in the database. This query provides information about how much memory is allocated for the vector data and how much of it is actually used.\n",
    "\n",
    "### Steps:\n",
    "1. **Memory allocation and usage:** The query returns the **allocated** (ALLOC_BYTES_MB) and **used** (USED_BYTES_MB) amount of memory in megabytes for each memory pool. \n",
    "2. **Populate-Status:** The status of the memory initialization is displayed by the field `populate_status`, which indicates the progress of the memory initialization. \n",
    "3. **Columns:**\n",
    " - `CON_ID`: Container ID of the database instance.\n",
    " - `POOL`: The name of the storage pool.\n",
    " - `ALLOC_BYTES_MB` and `USED_BYTES_MB`: Allocated and used memory in megabytes. \n",
    " - `populate_status`: Status of the memory pool.\n",
    "\n",
    "This query helps to monitor the memory resources for vector processing in the database and to identify bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e00d5-f972-4dfb-bdd6-9fe2f291ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "select CON_ID, POOL, \n",
    "round(ALLOC_BYTES/1024/1024,1) as ALLOC_BYTES_MB, \n",
    "round(USED_BYTES/1024/1024,1) as USED_BYTES_MB,\n",
    "populate_status\n",
    "from V$VECTOR_MEMORY_POOL \n",
    "order by 1,2\n",
    "\"\"\"\n",
    "df = pd.read_sql(sql, con=connection)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42308191",
   "metadata": {},
   "source": [
    "## Search without vectors: result/difference\n",
    "\n",
    "Traditional search methods, such as the keyword-based search, only compare texts on the basis of exact word matches. This means that only documents or data records containing the exact words entered are found. However, this method neglects the semantic relationship between terms. For example, a simple keyword search for \"house\" would possibly overlook \"building\" or \"apartment\" as these terms are not identical even though they have similar meanings.\n",
    "\n",
    "In contrast, the **vector search** uses embeddings that capture the semantic context of words. This makes it possible to find data records that are similar in content, even if the exact terms do not match. This makes searches much more flexible and intelligent, as semantic relationships are recognized and used.\n",
    "\n",
    "The difference in the results between a keyword-based search and a vector search is clear: While the conventional search only returns exact matches, the vector search can return content-relevant and similar entries that would remain undetected in a keyword-based search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90679766-0f62-4468-a8f0-1931ce0e7341",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a detailed introduction to the implementation and management of vector databases, from setting up the database environment to performing efficient similarity searches. Steps were taken to create a special tablespace and user, set up automatic generation of embeddings using triggers and enable parallel processing to optimize performance.\n",
    "\n",
    "A central element was the creation and management of a vector index that supports the search for semantic similarities based on embeddings. Various queries showed how top results can be filtered and sorted based on cosine distance. In addition, the accuracy of the vector index was verified and memory resources were monitored to ensure efficient processing of large datasets.\n",
    "\n",
    "The techniques demonstrated in this notebook illustrate the power of modern vector searches and show how the right indexing and memory configuration can make complex searches accurate and fast. These approaches are applicable in many areas, such as product recommendation, semantic text search or similarity search in image and real estate data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
