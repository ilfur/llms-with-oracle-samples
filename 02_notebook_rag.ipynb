{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352c50dc-3544-40fa-b554-7591cba5ca2c",
   "metadata": {},
   "source": [
    "![Banner](banner.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a70d37a7-3c3e-46ea-aaf1-0b6dafd23c30",
   "metadata": {},
   "source": [
    "# Exercise 2: Working with a Retrieval Augmented Generation (RAG) model\n",
    "\n",
    "This notebook introduces the concept of **Retrieval Augmented Generation (RAG)**, which combines the power of vector searches with text generation by Artificial Intelligence. The goal is to extract information from a document repository and augment it with a Generative AI model to provide contextualized answers.\n",
    "\n",
    "### Aims of the notebook:\n",
    "1. **Creating vectors for documents**: First, PDF documents are stored in the database, split into smaller blocks of text and converted into vectors using a pre-trained language model.\n",
    "2. **Creating vector indexes**: By creating a vector index on the generated embeddings, an efficient similarity search is enabled.\n",
    "3. **Retrieval of texts**: After vectorizing the document content, text snippets closest to the queries can be retrieved from the database.\n",
    "4. **Integration of Generative AI**: The generated text snippets are combined with a Generative AI model to create an augmented response consisting of both the existing documents and AI-generated content.\n",
    "5. **Creation of triggers and functions**: Automated processes for updating embeddings on new documents are implemented and tested.\n",
    "\n",
    "### Data basis:\n",
    "This notebook uses PDF documents as a basis, which are stored and processed in the database. These are realistic documents, such as scientific reports or frequently asked questions (FAQs). These are stored as **BLOB** data in the `RAG_TAB` table.\n",
    "\n",
    "Each PDF document is divided into **text chunks**, with each chunk containing a maximum of 100 words. These chunks are stored as text in the `RAG_CHUNKS` table. In addition, a **vector embedding** is generated for each chunk, which is used for semantic similarity searches. These embeddings make it possible to find sections of text that are semantically closest to a search query.\n",
    "\n",
    "The data stored in the tables includes:\n",
    "- **ID**: A unique identifier for each document.\n", 
    "- **Data (BLOB)**: The content of the uploaded PDF files.\n",
    "- **Chunk data**: Text snippets extracted from the PDF documents.\n",
    "- **Embedding**: The vector embeddings computed for each text snippet.\n",
    "\n",
    "This notebook shows how modern AI technologies can be used to efficiently search existing information from large sets of documents and augment it with generative models.\n",
    "\n",
    "Have fun & success!\n",
    "\n",
    "## Preparing the environment\n",
    "\n",
    "Before the actual processing can begin, some basic preparations must be made. This section describes how to install the required libraries and set up the connection to the Oracle database.\n",
    "\n",
    "### Installed packages:\n",
    "1. `oracledb`: This package allows you to access Oracle databases from Python and execute SQL queries. \n",
    "2. `ipython-sql`: Allows direct use of SQL within a Jupyter notebook.\n",
    "3. `pandas`: Used to display database queries in an easy-to-read DataFrame format.\n",
    "\n",
    "### Oracle database setup:\n",
    "- **Instant Client Initialization**: The Oracle Instant Client is initialized using the `oracledb.init_oracle_client()` function. The path to the required libraries is specified explicitly to ensure that the database connection works.\n",
    "- **Connection to the database**: The connection to the database is established by environment variables (`HOST_NAME` and `PDB_NAME`). These variables contain information about the host and database (PDB - Pluggable Database), which are combined to form a connection string (`dsn`).\n",
    "- **Connection confirmation**: If the connection has been successfully established, this is confirmed by the output of the connection details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe7a88b-c79c-44a0-b9b7-c1862442dd48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: oracledb in /opt/conda/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: cryptography>=3.2.1 in /opt/conda/lib/python3.11/site-packages (from oracledb) (42.0.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=3.2.1->oracledb) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.2.1->oracledb) (2.22)\n",
      "Requirement already satisfied: ipython-sql in /opt/conda/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.11/site-packages (from ipython-sql) (3.12.0)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.11/site-packages (from ipython-sql) (8.24.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in /opt/conda/lib/python3.11/site-packages (from ipython-sql) (2.0.30)\n",
      "Requirement already satisfied: sqlparse in /opt/conda/lib/python3.11/site-packages (from ipython-sql) (0.5.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.11/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy>=2.0->ipython-sql) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy>=2.0->ipython-sql) (3.0.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython->ipython-sql) (4.9.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prettytable->ipython-sql) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->ipython-sql) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->ipython-sql) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->ipython-sql) (0.2.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install oracledb \n",
    "!pip install ipython-sql\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "711e6308-3e44-446c-86b1-1916e5db1d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db23ai.subbb3fff175.quickcluster.oraclevcn.com/marcel.subbb3fff175.quickcluster.oraclevcn.com\n",
      "<oracledb.Connection to vector@db23ai.subbb3fff175.quickcluster.oraclevcn.com/marcel.subbb3fff175.quickcluster.oraclevcn.com>\n"
     ]
    }
   ],
   "source": [
    "import oracledb\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "pd.options.display.max_colwidth = 800\n",
    "\n",
    "d = '/home/jovyan/.jupyter/instantclient_23_5'\n",
    "oracledb.init_oracle_client(lib_dir=d)\n",
    "host = os.environ.get('HOST_NAME')\n",
    "pdb = os.environ.get('PDB_NAME')\n",
    "cs = host + '/' + pdb\n",
    "print(cs)\n",
    "# should be something like 'db23ai.subbb3fff175.quickcluster.oraclevcn.com/michael.subbb3fff175.quickcluster.oraclevcn.com'\n",
    "\n",
    "connection = oracledb.connect(user='vector', password='vector', dsn=cs)\n",
    "print(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a817758-16cd-4110-830a-7a9af231adea",
   "metadata": {},
   "source": [
    "## Script 00: Creating the document table\n",
    "\n",
    "This section creates the `RAG_TAB` table for saving documents in BLOB format. It contains:\n",
    "- **id (number)**: Unique identifier.\n",
    "- **data (blob)**: Saves the document contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72444484-8d90-4d8a-b7d4-d29eaa7c4093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "BEGIN\n",
    " EXECUTE IMMEDIATE('drop table if exists RAG_TAB purge');\n",
    " EXECUTE IMMEDIATE('create table RAG_TAB (id number, data blob)'); \n",
    "END;\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a08a1-7699-4805-9980-f33692667513",
   "metadata": {},
   "source": [
    "## Script 01: Inserting documents\n",
    "\n",
    "In this step, two PDF documents are inserted into the `RAG_TAB` table:\n",
    "- **Document 1**: *breast-cancer-facts-and-figures-2019-2020.pdf*\n",
    "- **Document 2**: *Coronavirus-FAQ.pdf*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e7233b-1ab1-4210-a98a-b63e674236df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n"
     ]
    }
   ],
   "source": [
    "sql= \"\"\"\n",
    "BEGIN\n",
    "  insert into RAG_TAB values(1, to_blob(bfilename('VEC_DUMP', 'breast-cancer-facts-and-figures-2019-2020.pdf')));  \n",
    "  insert into RAG_TAB values(2, to_blob(bfilename('VEC_DUMP', 'Coronavirus-FAQ.pdf')));\n",
    "  commit;\n",
    "END;\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f11a78-8a31-47ea-981e-875a082d7a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>[kB]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1360.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>104.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     [kB]\n",
       "0   1  1360.90\n",
       "1   2   104.94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql= \"\"\"\n",
    "select t.id, round(dbms_lob.getlength(t.data)/1024,2) \"[kB]\" from RAG_TAB t\n",
    "\"\"\"\n",
    "df = pd.read_sql(sql=sql, con=connection)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3721ce-bfe1-4aaa-9252-96ee95cf718f",
   "metadata": {},
   "source": [
    "## Script 02: Creating the `RAG_CHUNKS` table and inserting chunks\n",
    "\n",
    "In this step, the `RAG_CHUNKS` table is created, which stores the split document texts (chunks) and their embeddings.\n",
    "\n",
    "### Steps:\n",
    "1. **Creating the `RAG_CHUNKS` table**:\n",
    " - **doc_id**: Document ID assigned to the original document.\n",
    " - **chunk_id**: Unique ID for each chunk.\n",
    " - **chunk_data**: The text of the chunk (max. 4000 characters).\n",
    " - **chunk_embedding**: Vector embedding of the chunk.\n",
    "\n",
    "2. **Inserting the chunks and embeddings**:\n",
    " - The PDF data from `RAG_TAB` is broken down into smaller text blocks (chunks) (max. 100 words per chunk). \n",
    " - For each chunk, a vector embedding is created with the model `minilml6_model` and inserted into the table `RAG_CHUNKS`.\n",
    "\n",
    "### Model selection: minilml6_model\n",
    "\n",
    "In exercise 2, we use the model **`minilml6_model`**, which enables a particularly efficient calculation of vector embeddings. This model was chosen for its compact architecture and fast computation without sacrificing accuracy. It is ideal for scenarios in which large data sets need to be processed and resources such as computing power and storage space need to be used efficiently.\n",
    "\n",
    "### model delimitation\n",
    "\n",
    "- `distiluse-base-multilingual-cased-v2`: Precise, multilingual (including German), computationally intensive - ideal for semantic similarity.\n",
    "- `minilml6_model`: trained only for English texts, efficient, resource-saving - suitable for fast access to large amounts of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef8010",
   "metadata": {},
   "source": [
    "![title](img/end-to-end_pipeline_with_DBMS_VECTOR_CHAIN_package.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3911787-7097-4cc6-9164-9a4db46b9fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n"
     ]
    }
   ],
   "source": [
    "sql= \"\"\"\n",
    "begin\n",
    "   execute immediate ('drop table if exists RAG_CHUNKS purge');\n",
    "   execute immediate ('CREATE TABLE RAG_CHUNKS ('||\n",
    "     '  doc_id          NUMBER, '||\n",
    "     '  chunk_id        NUMBER, '||\n",
    "     '  chunk_data      VARCHAR2(4000), '||\n",
    "     '  chunk_embedding VECTOR )'\n",
    "   );\n",
    "end;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c27714a7-ef3e-4beb-8547-7167f809ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n",
      "Chunking and vectorizing took 9.5504 seconds\n"
     ]
    }
   ],
   "source": [
    "sql= \"\"\"\n",
    "begin\n",
    "   INSERT INTO RAG_CHUNKS\n",
    "   SELECT dt.id                      doc_id,\n",
    "       et.embed_id                chunk_id,\n",
    "       et.embed_data              chunk_data,\n",
    "       to_vector(et.embed_vector) chunk_embedding \n",
    "   FROM RAG_TAB dt,\n",
    "     dbms_vector_chain.utl_to_embeddings(\n",
    "         dbms_vector_chain.utl_to_chunks(dbms_vector_chain.utl_to_text(dt.data),json('{\n",
    "             \"by\" : \"words\",\n",
    "             \"max\" : \"100\",\n",
    "             \"overlap\" : \"0\",\n",
    "             \"split\" : \"recursively\",\n",
    "             \"language\" : \"american\",\n",
    "             \"normalize\":\"all\"}')),\n",
    "         json('{\"provider\":\"database\", \"model\":\"minilml6_model\"}')) t,\n",
    "         json_table(t.column_value, '$[*]' COLUMNS (embed_id NUMBER path '$.embed_id', embed_data VARCHAR2(4000) path '$.embed_data',\n",
    "                embed_vector clob path '$.embed_vector')) et;\n",
    "\n",
    "commit;\n",
    "end;\n",
    "\"\"\"\n",
    "\n",
    "tic = time.perf_counter()\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")\n",
    "toc = time.perf_counter()\n",
    "print(f\"Chunking and vectorizing took {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5eeac-89bf-4a9d-baf5-c05574d8afc4",
   "metadata": {},
   "source": [
    "## Script 03: Creating a compound trigger for `RAG_TAB`\n",
    "\n",
    "In this step, a **compound trigger** is created to ensure that new entries in `RAG_TAB` are also automatically transferred to the `RAG_CHUNKS` table. The trigger prevents data from becoming inconsistent between the two tables.\n",
    "\n",
    "### How the trigger works:\n",
    "1. **AFTER EACH ROW**: After a new row has been inserted in `RAG_TAB`, the new blob (document content) and ID are saved.\n",
    "2. **AFTER STATEMENT**: Once the insertion process is complete, the document is split into text chunks, a vector embedding is created for each chunk and this information is transferred to the `RAG_CHUNKS` table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a67b0a8-5126-4512-886a-f8e43b596dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n"
     ]
    }
   ],
   "source": [
    "sql= \"\"\"\n",
    "-- Compound trigger to avoid mismatch in rag_tab and rac_chunks!\n",
    "CREATE OR REPLACE TRIGGER INSERT_rag_tab\n",
    "FOR INSERT ON rag_tab\n",
    "COMPOUND TRIGGER \n",
    "the_new blob;\n",
    "new_id number;\n",
    "AFTER EACH ROW IS\n",
    "BEGIN\n",
    " the_new := :new.data;\n",
    " new_id  := :new.id;\n",
    "END AFTER EACH ROW;\n",
    "AFTER STATEMENT IS\n",
    "BEGIN\n",
    " INSERT INTO RAG_CHUNKS\n",
    " SELECT new_id                     doc_id,\n",
    "        et.embed_id                chunk_id,\n",
    "        et.embed_data              chunk_data,\n",
    "        to_vector(et.embed_vector) chunk_embedding\n",
    " FROM RAG_TAB dt,\n",
    "     dbms_vector_chain.utl_to_embeddings(\n",
    "         dbms_vector_chain.utl_to_chunks(dbms_vector_chain.utl_to_text(the_new),json('{\n",
    "             \"by\" : \"words\",\n",
    "             \"max\" : \"100\",\n",
    "             \"overlap\" : \"0\",\n",
    "             \"split\" : \"recursively\",\n",
    "             \"language\" : \"american\",\n",
    "             \"normalize\":\"all\"}')),\n",
    "         json('{\"provider\":\"database\", \"model\":\"minilml6_model\"}')) t,\n",
    "     json_table(t.column_value, '$[*]' COLUMNS (embed_id NUMBER path '$.embed_id', embed_data VARCHAR2(4000) path '$.embed_data',\n",
    "                embed_vector clob path '$.embed_vector')) et;\n",
    "END AFTER STATEMENT;\n",
    "END INSERT_rag_tab;\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72532fe0-5cf4-4c67-821c-b8aafcf3c3c8",
   "metadata": {},
   "source": [
    "## Script 03a: Inserting a new document in `RAG_TAB`\n",
    "\n",
    "In this step, another document is inserted into the table `RAG_TAB`:\n",
    "\n",
    "- **Document 3**: *breast-cancer-new.pdf*\n",
    "\n",
    "As soon as the document has been inserted, the previously created trigger ensures that the document is split into text chunks, vector embeddings are created and these are transferred to the `RAG_CHUNKS` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5407747-cc95-415c-86f1-c892a6cb9c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n",
      "Loading, chunking and vectorizing took 13.0958 seconds\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "BEGIN\n",
    "insert into RAG_TAB values(3, to_blob(bfilename('VEC_DUMP', 'breast-cancer-new.pdf')));\n",
    "commit;\n",
    "END; \n",
    "\"\"\"\n",
    "tic = time.perf_counter()\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")\n",
    "toc = time.perf_counter()\n",
    "print(f\"Loading, chunking and vectorizing took {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251dcdb8-65a2-4f98-a99a-51859cd1f89d",
   "metadata": {},
   "source": [
    "## Script 03b: Creation of a vector index on `RAG_CHUNKS`\n",
    "\n",
    "In this step, a **vector index** is created on the `chunk_embedding` column of the `RAG_CHUNKS` table to improve the efficiency of the similarity search based on vector embeddings.\n",
    "\n",
    "### Details:\n",
    "1. **Index creation**: The index `IDX_RAG_CHUNKS_EMBED` is created with a **Cosine distance** as metric and a target accuracy of 95%. \n",
    "2. **Check the index**: An SQL query is executed to check the newly created index and ensure that it was created correctly.\n",
    "3. **Retrieve the index parameters**: The parameters of the vector index are output in JSON format to view the structure and configuration of the index.\n",
    "\n",
    "Note: Once a **HNSW** index has been created, DML operations (e.g. INSERT, UPDATE) are no longer permitted on the indexed table. An **IVF index** could be used for DML operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "974f2273-c97f-463a-ac45-9a08aec23bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "create vector index IDX_RAG_CHUNKS_EMBED on RAG_CHUNKS(chunk_embedding) \n",
    " organization INMEMORY NEIGHBOR GRAPH\n",
    " distance COSINE\n",
    " with target accuracy 95\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b29165e1-93e6-4fc1-aa40-2fde08fc9014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX_NAME</th>\n",
       "      <th>INDEX_TYPE</th>\n",
       "      <th>INDEX_SUBTYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDX_RAG_CHUNKS_EMBED</td>\n",
       "      <td>VECTOR</td>\n",
       "      <td>INMEMORY_NEIGHBOR_GRAPH_HNSW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             INDEX_NAME INDEX_TYPE                 INDEX_SUBTYPE\n",
       "0  IDX_RAG_CHUNKS_EMBED     VECTOR  INMEMORY_NEIGHBOR_GRAPH_HNSW"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "SELECT INDEX_NAME, INDEX_TYPE, INDEX_SUBTYPE\n",
    "FROM USER_INDEXES\n",
    "WHERE INDEX_NAME='IDX_RAG_CHUNKS_EMBED'\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql=sql, con=connection)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35e69583-7a39-4afc-8307-421a74d7cdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"type\": \"HNSW\",\n",
      "    \"num_neighbors\": 32,\n",
      "    \"efConstruction\": 300,\n",
      "    \"distance\": \"COSINE\",\n",
      "    \"accuracy\": 95,\n",
      "    \"vector_type\": \"FLOAT32\",\n",
      "    \"vector_dimension\": 384,\n",
      "    \"degree_of_parallelism\": 1,\n",
      "    \"pdb_id\": 4,\n",
      "    \"indexed_col\": \"CHUNK_EMBEDDING\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "SELECT JSON_SERIALIZE(IDX_PARAMS returning varchar2 PRETTY) \"IDX_Params\"\n",
    "FROM VECSYS.VECTOR$INDEX\n",
    "where IDX_NAME = 'IDX_RAG_CHUNKS_EMBED'\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    res, =cursor.fetchone()\n",
    "    json_obj = json.loads(res)\n",
    "    pretty= json.dumps(json_obj, indent=4)\n",
    "    print(pretty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95fd48f-608c-4e7d-bb11-3eb9203940da",
   "metadata": {},
   "source": [
    "## Script 04: Functions for the integration of Generative AI (RAG)\n",
    "\n",
    "This section presents two variants of the function `rag_with_genai_function` that combines Generative AI with semantic similarity search in the stored document chunks. **However, only variant 2 is used in the workshop.",
    "\n",
    "### Variant 1: Generative AI with Oracle Cloud Integration (documentation only)\n",
    "This function uses **Oracle Generative AI** via the provided API. The steps include:\n",
    "1. **Create a vector embedding**: An embedding is generated for the input.\n",
    "2. **Search for similar chunks**: The most similar chunks from the saved PDF documents are determined based on the vector distance.\n",
    "3 **Generative AI response**: The generated text chunk is combined with a response from Oracle Generative AI. The text is sent to the **cohere.command** model service via an API request.\n",
    "4. **Return of the result**: The function returns the document chunk as well as the generative response.\n",
    "\n",
    "\n",
    "### Variant 2: External Generative AI integration with SSL (workshop variant)\n",
    "This function integrates **external Generative AI** via an HTTP API with SSL certificate. Only this variant is used in the workshop. The steps are:\n",
    "1. **Vector embedding**: A vector embedding is created for the input.\n",
    "2. **Search for chunks**: The most similar chunks from the `RAG_CHUNKS` table are retrieved.\n",
    "3. **API request to external service**: The request is sent to an external Generative AI model (e.g. Llama3.1) via an API endpoint.\n",
    "4. **Combine response**: The Generative AI response is combined with the document chunks and returned.\n",
    "\n",
    "This variant shows how an external Generative AI service is integrated into the Retrieval Augmented Generation (RAG) process and is used in the workshop."
   ]
  },
  {
   "cell_type": "raw",
   "id": "50a89d07-f2e7-4e61-814e-5f98bf98b1a1",
   "metadata": {},
   "source": [
    "### Variante 1\n",
    "### nur zu Dokumentationszwecken\n",
    "\n",
    "sql=\"\"\"\n",
    "create or replace Function rag_with_genai_function ( rag_input IN varchar2 )\n",
    "RETURN varchar2\n",
    "IS\n",
    " query_vector CLOB;\n",
    " text_variable VARCHAR2(1000) := rag_input;\n",
    " l_doc_id VARCHAR2(100);  \n",
    " input CLOB;\n",
    " params CLOB;\n",
    " output CLOB;\n",
    " long_text VARCHAR2(4000);\n",
    " cursor c1 is SELECT * FROM rag_chunks ORDER BY VECTOR_DISTANCE(CHUNK_EMBEDDING, query_vector, EUCLIDEAN_SQUARED) \n",
    "              FETCH FIRST 1 ROWS ONLY WITH TARGET ACCURACY 90;\n",
    "BEGIN\n",
    "  input := text_variable;\n",
    "  params := '{\n",
    "      \"provider\" : \"ocigenai\",\n",
    "      \"credential_name\" : \"OCI_CRED\", \n",
    "      \"url\" : \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/generateText\",\n",
    "      \"model\" : \"cohere.command\",\n",
    "      \"inferenceRequest\": {\n",
    "          \"maxTokens\": 300,\n",
    "          \"temperature\": 1\n",
    "        }\n",
    "  }';\n",
    " \n",
    "  SELECT vector_embedding(minilml6_model using text_variable as data) into query_vector;\n",
    "  for row_1 in c1 loop\n",
    "      long_text := '*** Internal PDF Search: \\n\\n'||row_1.chunk_data||' \\n\\n';\n",
    "  end loop;\n",
    "\n",
    "  output := DBMS_VECTOR_CHAIN.UTL_TO_GENERATE_TEXT(input, json(params));\n",
    "\n",
    "  long_text := long_text||'*** Generative AI Response:\\n\\n'||output;\n",
    "\n",
    "  return (long_text);\n",
    "\n",
    "END;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d81a6195-314d-47ec-8a53-9249f8a2dcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n"
     ]
    }
   ],
   "source": [
    "### variant 2\n",
    "### accesses the internal GenAI service via an external name and SSL certificate\n",
    "\n",
    "sql=\"\"\"\n",
    "CREATE OR REPLACE FUNCTION rag_with_genai_function( rag_input in varchar2) return varchar2\n",
    "AS\n",
    "    l_url             VARCHAR2(400) := 'http://olama.meinnetzwerk.com/api/chat';\n",
    "    req               utl_http.req;\n",
    "    resp              utl_http.resp;\n",
    "    body              VARCHAR2(4000);\n",
    "    buffer            VARCHAR2(8192);\n",
    "    long_text         VARCHAR2(32767);\n",
    "    query_vector      CLOB;\n",
    "    cursor c1 is SELECT * FROM rag_chunks ORDER BY VECTOR_DISTANCE(CHUNK_EMBEDDING, query_vector, EUCLIDEAN_SQUARED) \n",
    "              FETCH FIRST 1 ROWS ONLY WITH TARGET ACCURACY 90; \n",
    "BEGIN\n",
    "   -- in case you are behind a proxy, please uncomment the following line after setting the correct proxy address\n",
    "   -- utl_http.set_proxy('http://username:passwd@192.168.22.33:5678');\n",
    "   body := '{\"model\": \"llama3.1:latest\",\"messages\": [{\"role\": \"system\", \"content\": \"you are a lightly arrogant medical doctor\"},' || \n",
    "                                                    '{\"role\": \"user\",   \"content\": \"'|| rag_input ||'\"}],' ||\n",
    "\t       '\"stream\": false, \"options\": {\"use_mmap\": true,\"use_mlock\": true,\"num_thread\": 8}}';\n",
    "           \n",
    "   req := utl_http.begin_request(l_url, 'POST', 'HTTP/1.1');\n",
    "   utl_http.set_header(req, 'Accept', '*/*');\n",
    "   utl_http.set_header(req, 'Content-Type', 'application/json');\n",
    "   utl_http.set_header(req, 'Content-Length', length(body));\n",
    "   utl_http.write_text(req, body);\n",
    "   \n",
    "   resp := utl_http.get_response(req);\n",
    "   BEGIN\n",
    "      utl_http.read_text(resp, buffer);\n",
    "   EXCEPTION\n",
    "      WHEN utl_http.end_of_body THEN\n",
    "         utl_http.end_response(resp);\n",
    "   END;\n",
    "   buffer := json_value (buffer, '$.message.content' returning varchar2);\n",
    "\n",
    "   SELECT vector_embedding(minilml6_model using rag_input as data) into query_vector;\n",
    "   for row_1 in c1 loop\n",
    "      long_text := '*** Internal PDF Search: \\n\\n'||row_1.chunk_data||' \\n\\n';\n",
    "   end loop;\n",
    "\n",
    "   long_text := long_text||'*** Generative AI Response:\\n\\n'||buffer;\n",
    "\n",
    "   return (long_text);\n",
    "END;\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514168b8-58f7-411f-b56a-ea7ddb1d24b0",
   "metadata": {},
   "source": [
    "## Script 05: Network configuration: Assignment of access rights\n",
    "\n",
    "In this step, the network configuration is adjusted to ensure that the user `vector` has the necessary rights to access external network requests. This is important to enable API calls to external Generative AI services.\n",
    "\n",
    "### SQL command:\n",
    "- **DBMS_NETWORK_ACL_ADMIN.APPEND_HOST_ACE**: This command adds a network access control list (ACL) that gives the user `vector` permission to make network connections.\n",
    " - **host**: The host name, here `'*'`, allows connections to all hosts.\n",
    " - **privilege_list**: The list of authorizations, here the privilege `connect` is granted so that the user `vector` can establish connections to external services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b97e680-9a20-4750-be56-4e9519475d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "BEGIN\n",
    "  DBMS_NETWORK_ACL_ADMIN.APPEND_HOST_ACE(\n",
    "    host => '*',\n",
    "    ace => xs$ace_type(privilege_list => xs$name_list('connect'),\n",
    "                       principal_name => 'vector',\n",
    "                       principal_type => xs_acl.ptype_db));\n",
    "END;\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d70639-333a-465a-95f9-82f076e6fddc",
   "metadata": {},
   "source": [
    "## Script 06: Creation of OCI access data for API usage\n",
    "\n",
    "In this step, a **credential** is created for access to Oracle Cloud Infrastructure (OCI) services. These credentials are required to use the Generative AI functions in the OCI\n",
    "\n",
    "### SQL command:\n",
    "- **Creation of a JSON object**: A JSON object is created that contains the necessary OCI access data:\n",
    " - **user_ocid**: The unique identifier of the user in OCI.\n",
    " - **tenancy_ocid**: The identifier of the tenancy (the OCI environment).\n",
    " - **compartment_ocid**: The identifier of the compartment in which the resources are located.\n",
    " - **private_key**: The private key required for authentication.\n",
    " - **fingerprint**: The fingerprint of the public key related to the private key.\n",
    "  \n",
    "- **Creation of the OCI credential**: The OCI credentials are created using the `dbms_vector_chain.create_credential` command and stored under the name `'OCI_CRED'`. These credentials are later used to authenticate to the OCI Generative AI service."
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "id": "1604dbee-e747-408a-aef2-2a9354d75eac",
   "metadata": {},
   "source": [
    "sql=\"\"\"\n",
    "declare\n",
    "  jo json_object_t;\n",
    "begin\n",
    "  jo := json_object_t();\n",
    "  jo.put('user_ocid','<user ocid>');\n",
    "  jo.put('tenancy_ocid','<tenancy ocid>');\n",
    "  jo.put('compartment_ocid','<compartment ocid>');\n",
    "  jo.put('private_key','<private key>');\n",
    "  jo.put('fingerprint','<fingerprint>');\n",
    "  dbms_output.put_line(jo.to_string);\n",
    "  dbms_vector_chain.create_credential(\n",
    "    credential_name   => 'OCI_CRED',\n",
    "    params            => json(jo.to_string));\n",
    "end;\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b3b7c-6b12-4580-9bc5-9bd1b1ce7556",
   "metadata": {},
   "source": [
    "## Checking the stored access data (credentials)\n",
    "\n",
    "In this step, a query is executed to check the **credentials** (access data) stored in the database.\n",
    "\n",
    "### SQL query:\n",
    "- **owner**: Displays the owner of the credentials (e.g. the user under which the credentials were created).\n",
    "- **credential_name**: The name of the stored credential, in this case the credentials should be `OCI_CRED`, which was previously created.\n",
    "- **enabled**: Indicates whether the saved credentials are enabled and available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e046832b-8e29-4515-9e5b-2b82eab08d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OWNER</th>\n",
       "      <th>CREDENTIAL_NAME</th>\n",
       "      <th>ENABLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VECTOR</td>\n",
       "      <td>OCI_CRED</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    OWNER CREDENTIAL_NAME ENABLED\n",
       "0  VECTOR        OCI_CRED    TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "select owner,credential_name, enabled from dba_credentials\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql=sql, con=connection)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b73abe-8471-4526-a3b1-97cc53edb379",
   "metadata": {},
   "source": [
    "## Perform a vector search based on a search text\n",
    "\n",
    "In this section, a semantic search is performed, searching the embedded chunks that are most similar to the entered search text\n", "\n",
    "\n",
    "### Steps:\n",
    "1. **Creation of an embedding for the search text**:\n",
    " - The entered search text (`suchtext`) is converted into a vector embedding using the `MINILML6_MODEL` model. This is saved in the variable `query_vector`.\n",
    "   \n",
    "2. **Search for the most similar chunks**:\n",
    " - The query searches the `RAG_CHUNKS` table and compares the stored embeddings of the chunks with the search text embedding using the **Cosine-Distance**.\n",
    " - The two most similar chunks for each document ID are retrieved, with the results sorted by vector distance.\n",
    "\n",
    "3. **Display results**:\n",
    " - The results of the query are displayed in a DataFrame and contain the **doc_id**, **chunk_id** and the corresponding **chunk_data** (text section).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d694ca40-a683-42c7-acd1-a99d4f0b7664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suchtext hier einfügen can men get breast cancer too ?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>CHUNK_ID</th>\n",
       "      <th>CHUNK_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>Male breast cancer \\nBreast cancer in men is r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>prostate cancer, age, obesity and smoking. In ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOC_ID  CHUNK_ID                                         CHUNK_DATA\n",
       "0       1        86  Male breast cancer \\nBreast cancer in men is r...\n",
       "1       3        47  prostate cancer, age, obesity and smoking. In ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suchtext = input(\"enter searh text here\")\n",
    "\n",
    "sql1 = \"\"\"\n",
    " SELECT vector_embedding(MINILML6_MODEL using :suchtext as data) from dual\n",
    "\"\"\"\n",
    "\n",
    "sql2 = \"\"\"\n",
    "SELECT doc_id, chunk_id, chunk_data\n",
    " FROM RAG_CHUNKS\n",
    " ORDER BY vector_distance(chunk_embedding , :query_vector, COSINE) \n",
    " FETCH FIRST 2 PARTITIONS BY doc_id, 1 ROWS ONLY\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    query_vector = cursor.var(oracledb.DB_TYPE_VECTOR)    \n",
    "    cursor.execute(sql1, suchtext=suchtext)\n",
    "    query_vector, =cursor.fetchone()\n",
    "    \n",
    "    df = pd.read_sql(sql2, params={'query_vector': query_vector}, con=connection)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99861505-882c-4dd0-ad93-5f9ef103e693",
   "metadata": {},
   "source": [
    "\n",
    "## Generative AI response based on a search text: \n",
    "### Comparison of found document chunks with the general knowledge of the AI\n",
    "\n",
    "In this section, the previously created function `rag_with_genai_function` is used to generate an extended answer that combines both relevant text sections from the stored documents and a Generative AI answer.", "\n",
    "\n",
    "### Steps:\n",
    "1. **Call the `rag_with_genai_function`**:\n",
    " - The entered search text (`suchtext`) is passed to the `rag_with_genai_function` function. This function searches for the most similar chunks in the table `RAG_CHUNKS`, based on the cosine distance.\n",
    "   \n",
    "2. **Generative AI response**:\n",
    " - In addition to the semantic search for relevant chunks, a Generative AI response is generated via the external Generative AI service. This response is combined with the found text section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecce1bd3-94bf-4d9b-a8a7-194a7c693f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Internal PDF Search: \n",
      "\n",
      "Male breast cancer \n",
      "Breast cancer in men is rare, accounting for less than 1% \n",
      "of breast cancer cases in the US. However, since 1975, the \n",
      "incidence rate has increased slightly, from 1.0 case per \n",
      "100,000 men during 1975-1979 to 1.2 cases per 100,000 \n",
      "men during 2012-2016.\n",
      "\n",
      "41\n",
      "\n",
      "Men are more likely than women \n",
      "(51% versus 36%) to be diagnosed with advanced \n",
      "(regional- or distant-stage) breast cancer, \n",
      "8\n",
      "\n",
      "which likely \n",
      "\n",
      "*** Generative AI Response:\n",
      "\n",
      "Yes, men can indeed develop breast cancer. (I mean, it's not as common as in women, of course, but still.) Male breast cancer, also known as gynecomastia-induced carcinoma, accounts for about 1% of all breast cancer cases.\n",
      "\n",
      "Now, I know what you're thinking: \"But doctor, isn't male breast cancer extremely rare?\" Ah, yes... well, relatively speaking. (Smirk) While it's true that men are much less likely to develop breast cancer than women, there is still a small but significant risk factor, especially for certain subpopulations.\n",
      "\n",
      "In fact, I've had several patients over the years who have presented with male breast cancer. It's usually linked to genetic predisposition, hormonal imbalances (such as Klinefelter syndrome or hypogonadism), radiation exposure, and, yes, even a family history of breast cancer in women.\n",
      "\n",
      "Now, don't get me wrong â male breast cancer is still an uncommon diagnosis. But it's essential for men to be aware of the risks, especially if they have a family history or exhibit any symptoms, such as lumps or skin changes around the nipple.\n",
      "\n",
      "So, there you have it. Male breast cancer is not entirely mythical; it's just... well, less common than its female counterpart. (Smiling confidently) Trust me, I know what I'm talking about here. After all, I did attend Harvard Medical School and specialize in oncology.\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "select rag_with_genai_function(:suchtext) from dual\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql, suchtext=suchtext)\n",
    "    res, =cursor.fetchone()\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5889488-0f6d-45b4-aec7-b744b2db0648",
   "metadata": {},
   "source": [
    "## Generative AI response based on a search text:\n",
    "### RAG, retrieval augmented generation\n",
    "In this section, the text sections found by vector search are transmitted as a pre-filtered knowledge base\n",
    "The query may only be answered with the transmitted documents, not with the (perhaps questionable) general knowledge of the AI.\n",
    "\n",
    "A function real_rag_with_genai is created, which is similar to the previous function rag_with_genai_function. However, the new function real_rag_with_genai does not output the two results for comparison, but transmits the result of the vector search as a JSON parameter to the GenAI query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4abfd12-e54e-4a7b-98ce-b1d47abeb6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL execution successful\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "CREATE OR REPLACE FUNCTION real_rag_with_genai( rag_input in varchar2) return varchar2\n",
    "AS\n",
    "    l_url             VARCHAR2(400) := 'http://olama.meinnetzwerk.com/api/chat';\n",
    "    req               utl_http.req;\n",
    "    resp              utl_http.resp;\n",
    "    body1             VARCHAR2(1000);\n",
    "    body2             VARCHAR2(1000);\n",
    "    body3             VARCHAR2(1000);\n",
    "    body4             VARCHAR2(1000);\n",
    "    buffer            VARCHAR2(8192);\n",
    "    long_text         VARCHAR2(32767);\n",
    "    query_vector      CLOB;\n",
    "    cursor c1 is SELECT * FROM rag_chunks ORDER BY VECTOR_DISTANCE(CHUNK_EMBEDDING, query_vector, EUCLIDEAN_SQUARED) \n",
    "              FETCH FIRST 1 ROWS ONLY WITH TARGET ACCURACY 90; \n",
    "BEGIN\n",
    "   -- defining the right prompt for RAG: specify what data to use and how to answer   \n",
    "   body1 := '{\"model\": \"llama3.1:latest\",\"messages\": [{\"role\": \"system\", \"content\": \" '||\n",
    "   'Your answers should begin with the phrase ''According to the information found in my database''.' || \n",
    "   'Please answer the following question only with information given in the provided DOCUMENTS\"} ,' ;\n",
    "   body2 := '{\"role\": \"system\", \"content\": \"DOCUMENTS: {{ Not much useful information }} \"} , ' ;\n",
    "   body3 := '{\"role\": \"user\",   \"content\": \"'|| rag_input ||'\"}],' ;\n",
    "   body4 :=  '\"stream\": false, \"options\": {\"use_mmap\": true,\"use_mlock\": true,\"num_thread\": 8}}';\n",
    "           \n",
    "   -- now, take the found chunks from the vector search as input to the genAI enquiry\n",
    "   SELECT vector_embedding(minilml6_model using rag_input as data) into query_vector;\n",
    "   long_text := body1||body2 ;\n",
    "   for row_1 in c1 loop\n",
    "      long_text := long_text||'{\"role\": \"system\", \"content\": \"DOCUMENTS: {{'||replace(row_1.chunk_data,chr(10),' ')||' }} \"} , ';\n",
    "   end loop;\n",
    "   long_text := long_text||body3||body4;\n",
    "\n",
    "   -- in case you are behind a proxy, please uncomment the following line after setting the correct proxy address\n",
    "   -- utl_http.set_proxy('http://username:passwd@192.168.22.33:5678');\n",
    "   req := utl_http.begin_request(l_url, 'POST', 'HTTP/1.1');\n",
    "   utl_http.set_header(req, 'Accept', '*/*');\n",
    "   utl_http.set_header(req, 'Content-Type', 'application/json');\n",
    "   utl_http.set_header(req, 'Content-Length', length(long_text));\n",
    "   utl_http.write_text(req, long_text);\n",
    "\n",
    "   -- now, call the genAI with the users enquiry plus found information\n",
    "   resp := utl_http.get_response(req);\n",
    "   BEGIN\n",
    "      utl_http.read_text(resp, buffer);\n",
    "   EXCEPTION\n",
    "      WHEN utl_http.end_of_body THEN\n",
    "         utl_http.end_response(resp);\n",
    "   END;\n",
    "   buffer := json_value (buffer, '$.message.content' returning varchar2);\n",
    "\n",
    "   return (buffer);\n",
    "END;\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql)\n",
    "    if cursor.warning :\n",
    "        print(cursor.warning)\n",
    "    else :\n",
    "        print(\"SQL execution successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c79e9734-cdbe-4626-b87f-4a29eef40314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the information found in my database, yes, men can get breast cancer. In fact, it's stated that \"Breast cancer in men is rare, accounting for less than 1% of breast cancer cases in the US.\"\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "select real_rag_with_genai(:suchtext) from dual\n",
    "\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:     \n",
    "    cursor.execute(sql, suchtext=suchtext)\n",
    "    res, =cursor.fetchone()\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90679766-0f62-4468-a8f0-1931ce0e7341",
   "metadata": {},
   "source": [
    "## summary\n",
    "\n",
    "In this notebook, the combination of vector search and generative AI was presented. Documents were stored in the database, divided into text chunks and provided with vector embeddings. With the help of a vector index, relevant text sections could be found efficiently.\n",
    "\n",
    "The function `rag_with_genai_function` made it possible to retrieve semantically similar document content and supplement it with a Generative AI response. This method provides a powerful solution for answering complex queries by combining the strengths of retrieval and Generative AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
